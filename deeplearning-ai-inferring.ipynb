{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inferring\nIn this lesson, you will infer sentiment and topics from product reviews and news articles.\n\n## Setup","metadata":{}},{"cell_type":"code","source":"import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')","metadata":{"height":132},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model's output\n    )\n    return response.choices[0].message[\"content\"]","metadata":{"height":164},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Product review text","metadata":{}},{"cell_type":"code","source":"lamp_review = \"\"\"\nNeeded a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\n\"\"\"","metadata":{"height":200},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"chatgpt_review = \"\"\"\nBrains aren't just a neural network. They consist of very chaotically connected expert systems, all of which serve one specific purpose. GI (without the A) results from the interactions between the brains expert systems. One for language, one for hunger, one for emotions, etc. When it call comes together, it results in cognition. That is so fundamentally different from how a computational neural network works as a data structure, in its extremely structured and clinically perfect way. Real neurons don't have activation functions, they have voltage potential. The propagation of signals in the brain is subject to dozens of chemicals, if not hundreds. Every neuron has a myriad of receptors for cannabinoids, neurotransmitters, and so on. If you want to simulate a real brain, you also need to simulate a physical environment for it. A simulation that includes temperature, blood content, blood pressure, chemical presence and so on. These chemicals are needed in the brain to regulate emotions and facilitate focus and alertness. The absence of all chemical influences on a neural network might keep it from ever developing AGI. We don't know these things, so I find it a little naive to claim that GPT-4 is anywhere even remotely, close to AGI or what we would consider a brain.\n> It fundamentally does not get more intelligent after training is done.\n\"\"\"","metadata":{"height":96},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Sentiment (positive/negative)","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":149},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"The sentiment of the product review is positive.\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nReview text: '''{chatgpt_review}'''\n\"\"\"\n\nresponse2 = get_completion(prompt)\nprint(response2)","metadata":{"height":166},"execution_count":17,"outputs":[{"name":"stdout","output_type":"stream","text":"The sentiment of the product review is negative.\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nWhat is the sentiment of the following product review, \nwhich is delimited with triple backticks?\n\nGive your answer as a single word, either \"positive\" \\\nor \"negative\".\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":200},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"positive\n"}]},{"cell_type":"markdown","source":"## Identify types of emotions","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify a list of emotions that the writer of the \\\nfollowing review is expressing. Include no more than \\\nfive items in the list. Format your answer as a list of \\\nlower-case words separated by commas.\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":183},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"satisfied, pleased, grateful, impressed, happy\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify a list of emotions that the writer of the \\\nfollowing review is expressing. Include no more than \\\nfive items in the list. Format your answer as a list of \\\nlower-case words separated by commas.\n\nReview text: '''{chatgpt_review}'''\n\"\"\"\nresponse2 = get_completion(prompt)\nprint(response2)","metadata":{"height":183},"execution_count":18,"outputs":[{"name":"stdout","output_type":"stream","text":"chaotic, specific, different, perfect, naive\n"}]},{"cell_type":"markdown","source":"First of all, none of the output are emotions. They are actually adjectives.\n\nAnd second, not all of the adjectives match what the comment talks about. The comment is: specific and different, but not chaotic, perfect nor naive.","metadata":{"height":30}},{"cell_type":"markdown","source":"## Identify anger","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nIs the writer of the following review expressing anger?\\\nThe review is delimited with triple backticks. \\\nGive your answer as either yes or no.\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":166},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"No\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nIs the writer of the following review expressing anger?\\\nThe review is delimited with triple backticks. \\\nGive your answer as either yes or no.\n\nReview text: '''{chatgpt_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":166},"execution_count":20,"outputs":[{"name":"stdout","output_type":"stream","text":"No\n"}]},{"cell_type":"markdown","source":"## Extract product and company name from customer reviews","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify the following items from the review text: \n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Item\" and \"Brand\" as the keys. \nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\n  \nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":285},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"{\n\n  \"Item\": \"lamp\",\n\n  \"Brand\": \"Lumina\"\n\n}\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify the following items from the review text: \n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Item\" and \"Brand\" as the keys. \nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\n  \nReview text: '''{chatgpt_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":285},"execution_count":21,"outputs":[{"name":"stdout","output_type":"stream","text":"{\n\n  \"Item\": \"GPT-4\",\n\n  \"Brand\": \"unknown\"\n\n}\n"}]},{"cell_type":"markdown","source":"Yes, correct!","metadata":{"height":30}},{"cell_type":"code","source":"chatgpt_review2 = \"\"\"\nI think we have a good chance for Gemini being a massive breakthrough. Deepmind is to be taken seriously. If they really combine their Alpha X techniques with LLMs and go for scale, I'm not sure what the result will be. If I understand Demis Hassabis correctly, they are about to not just take the next token, but to perform extensive tree search, before deiciding which path to go down. In his words (paraphrasing): Not just the most probable token, but the best one.\\n\\nI'm holding back on the hype (and sheer potential terror of it), but it might be big. It might also turn out to be nothing. Engineering God is hard work. There are bound to be issues on the way.\n\"\"\"","metadata":{"height":79},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify the following items from the review text: \n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Item\" and \"Brand\" as the keys. \nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\n  \nReview text: '''{chatgpt_review2}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":285},"execution_count":26,"outputs":[{"name":"stdout","output_type":"stream","text":"{\n\n  \"Item\": \"unknown\",\n\n  \"Brand\": \"unknown\"\n\n}\n"}]},{"cell_type":"markdown","source":"Too bad this is wrong. The answer should have been Gemini and DeepMind. So this is a window into the type of understanding this model has. And therefore, opportunity for interpreting/retraining.","metadata":{"height":30}},{"cell_type":"markdown","source":"## Doing multiple tasks at once","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify the following items from the review text: \n- Sentiment (positive or negative)\n- Is the reviewer expressing anger? (true or false)\n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\nFormat the Anger value as a boolean.\n\nReview text: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":336},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"{\n\n  \"Sentiment\": \"positive\",\n\n  \"Anger\": false,\n\n  \"Item\": \"lamp\",\n\n  \"Brand\": \"Lumina\"\n\n}\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify the following items from the review text: \n- Sentiment (positive or negative)\n- Is the reviewer expressing anger? (true or false)\n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\nFormat the Anger value as a boolean.\n\nReview text: '''{chatgpt_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":336},"execution_count":27,"outputs":[{"name":"stdout","output_type":"stream","text":"{\n\n  \"Sentiment\": \"negative\",\n\n  \"Anger\": false,\n\n  \"Item\": \"unknown\",\n\n  \"Brand\": \"unknown\"\n\n}\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nIdentify the following items from the review text: \n- Sentiment (positive or negative)\n- Is the reviewer expressing anger? (true or false)\n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\nFormat the Anger value as a boolean.\n\nReview text: '''{chatgpt_review2}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":336},"execution_count":28,"outputs":[{"name":"stdout","output_type":"stream","text":"{\n\n  \"Sentiment\": \"positive\",\n\n  \"Anger\": false,\n\n  \"Item\": \"unknown\",\n\n  \"Brand\": \"unknown\"\n\n}\n"}]},{"cell_type":"markdown","source":"## Inferring topics","metadata":{}},{"cell_type":"code","source":"story = \"\"\"\nIn a recent survey conducted by the government, \npublic sector employees were asked to rate their level \nof satisfaction with the department they work at. \nThe results revealed that NASA was the most popular \ndepartment with a satisfaction rating of 95%.\n\nOne NASA employee, John Smith, commented on the findings, \nstating, \"I'm not surprised that NASA came out on top. \nIt's a great place to work with amazing people and \nincredible opportunities. I'm proud to be a part of \nsuch an innovative organization.\"\n\nThe results were also welcomed by NASA's management team, \nwith Director Tom Johnson stating, \"We are thrilled to \nhear that our employees are satisfied with their work at NASA. \nWe have a talented and dedicated team who work tirelessly \nto achieve our goals, and it's fantastic to see that their \nhard work is paying off.\"\n\nThe survey also revealed that the \nSocial Security Administration had the lowest satisfaction \nrating, with only 45% of employees indicating they were \nsatisfied with their job. The government has pledged to \naddress the concerns raised by employees in the survey and \nwork towards improving job satisfaction across all departments.\n\"\"\"","metadata":{"height":472},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"story2 = \"\"\"\nJoking aside, if you can't tell the difference, does it matter? Maybe quantity will bring quality. Enough self referencing and agents going around and who knows.\n\"spicy\" does a lot of work here.  As I understand it (which is minimal) the model comprises layers of transformers that handle varying contextual scopes and the vast quantities of training data and parameters of the system result in emergent capability we can't really explain. We can explain autocorrect.  People like to focus on the autoregressive decoding aspect and say silly things like \"it's just predicting the next word\", but this predicting is done by the model using the context of every word so far in the conversation. The \"bag of words\" it comes up with and assigns probabilities to are chosen carefully and in ways we don't understand.\nBard sucks. Unless it's gotten better in the past couple weeks. Maybe I was too hard on it, but I gave it some pretty simple coding questions and it has absolutely no idea what was going on. It's got a long way to go, at least for my purposes.\n>AGI is decades, if not centuries away\n\"\"\"","metadata":{"height":130},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Infer 5 topics","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nDetermine five topics that are being discussed in the \\\nfollowing text, which is delimited by triple backticks.\n\nMake each item one or two words long. \n\nFormat your response as a list of items separated by commas.\n\nText sample: '''{story}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":217},"execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"1. Government survey\n\n2. Department satisfaction rating\n\n3. NASA\n\n4. Social Security Administration\n\n5. Job satisfaction improvement\n"}]},{"cell_type":"code","source":"prompt = f\"\"\"\nDetermine five topics that are being discussed in the \\\nfollowing text, which is delimited by triple backticks.\n\nMake each item one or two words long. \n\nFormat your response as a list of items separated by commas.\n\nText sample: '''{story2}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":217},"execution_count":31,"outputs":[{"name":"stdout","output_type":"stream","text":"1. Autoregressive decoding\n\n2. Transformers\n\n3. Training data\n\n4. AGI (Artificial General Intelligence)\n\n5. Bard (referring to a specific program or system)\n"}]},{"cell_type":"markdown","source":"Pretty accurate. Though items 4 and 5 are not two words long, but helpful when answering first requirement of ask.","metadata":{"height":30}},{"cell_type":"code","source":"response.split(sep=',')","metadata":{"height":30},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":["['1. Government survey\\n2. Department satisfaction rating\\n3. NASA\\n4. Social Security Administration\\n5. Job satisfaction improvement']"]},"metadata":{}}]},{"cell_type":"code","source":"topic_list = [\n    \"nasa\", \"local government\", \"engineering\", \n    \"employee satisfaction\", \"federal government\"\n]","metadata":{"height":81},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Make a news alert for certain topics","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nDetermine whether each item in the following list of \\\ntopics is a topic in the text below, which\nis delimited with triple backticks.\n\nGive your answer as list with 0 or 1 for each topic.\\\n\nList of topics: {\", \".join(topic_list)}\n\nText sample: '''{story}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)","metadata":{"height":234},"execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"[1, 0, 0, 1, 1]\n"}]},{"cell_type":"code","source":"topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\nif topic_dict['nasa'] == 1:\n    print(\"ALERT: New NASA story!\")","metadata":{"height":79},"execution_count":15,"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m topic_dict \u001b[38;5;241m=\u001b[39m {i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;28mint\u001b[39m(i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39msplit(sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m topic_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnasa\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALERT: New NASA story!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[15], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m topic_dict \u001b[38;5;241m=\u001b[39m {i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;28mint\u001b[39m(\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39msplit(sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m topic_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnasa\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALERT: New NASA story!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","source":"## Try experimenting on your own!","metadata":{}},{"cell_type":"code","source":"","metadata":{"height":30},"execution_count":null,"outputs":[]}]}